---
title: "Statistical Models - Project"
author: "Rosa Maria Bruno, Roberto Cerminara, Lorenzo Piattoli"
output: pdf_document
date: "Marzo 2025"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduzione

Il dataset oggetto di studio (*fonte: https://archive.ics.uci.edu/dataset/45/heart+disease - dataset Cleveland*) riguarda 303 pazienti che sono stati sottoposti ad una serie di esami clinici per vedere se il dolore al petto da loro riscontrato fosse dovuto ad una cardiopatia. Il dataset contiene 13 variabili esplicative, comprendenti risultati di test diagnostici e altre informazioni rilevanti del paziente, e una varibile di risposta che rappresenta il risultato di un esame volto a valutare la presenza o meno di una malattia cardiaca. L'obiettivo del progetto è quello di studiare la relazione che intercorre tra tali caratteristiche del paziente e la presenza o meno di una cardiopatia.

Le 13 variabili esplicative e la variabile di risposta sono elencate di seguito:

* ***age***: età espressa in anni
* ***sex***: genere (*0 = donnna, 1 = uomo*)
* ***cp***: tipo di dolore toracico (*1 = angina tipica, 2 = angina atipica, 3 = non anginoso, 4 = asintomatico*)
* ***trestbps***: pressione sanguigna a riposo misurata in mmHg
* ***chol***: colesterolo sierico misurato in mg/dl
* ***fbs***: glicemia a digiuno (*0 se $\le120$ mg/dl, 1 altrimenti*)
* ***restecg***: risultati dell'elettrocardiogramma a riposo (*0 = normale, 1 = anomalia dell'ST-T, 2 = probabile/certa ipertrofia ventricolare sinistra*)
* ***thalach***: frequenza cardiaca massima
* ***exang***: angina indotta da esercizio fisico (*0 = no, 1 = sì*)
* ***oldpeak***: depressione ST indotta da esercizio fisico rispetto al riposo 
* ***slope***: pendenza del segmento ST di picco dell'esercizio fisico (*1 = sopraslivellamento, 2 = piatta, 3 = sottoslivellamento*)
* ***ca***: numero di principali vasi sanguigni colorati (da 0 a 3) mediante fluoroscopia
* ***thal***: test da sforzo al tallio (*3 = normale, 6 = difetto fisso, 7 = difetto reversibile*)
* ***num*** = variabile di risposta che indica la presenza o meno di una malattia cardiaca (*0 = assenza, 1-2-3-4 = presenza*)

## Importazione dati

Innanzitutto, riportiamo di seguito le librerie necessarie per l'esecuzione del codice:
```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(scales)
library(gridExtra)
library(car)
library(MASS)
library(sjPlot)
library(caret)
library(pROC)
```

Successivamente, importiamo il dataset e creiamo la variabile di risposta binaria *resp* che assume valore 1 nel caso di presenza di una malattia al cuore e 0 altrimenti. Inoltre, ai fini di una corretta analisi trasformiamo tutte le variabili categoriche da numeriche a fattori.

```{r }
#### Importazione dati ####
#heart = read.table(file.choose(), header=F, sep=",", dec=".")
heart = read.table("/Users/lorenzo/Documents/Master/Moduli/Statistical Models/Progetto/heart.csv", header=F, sep=",", dec=".")
colnames(heart)=c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope", "ca", "thal","num")

#### Creazione variabile di risposta binaria ####
heart_bin = heart %>% mutate(resp=factor(ifelse(num>0,1,0)))
heart_bin = heart_bin[,-14] #eliminazione variabile "num"

#### Trasformazione delle var. categoriche da numeriche a fattori ####
heart_bin$sex = factor(heart_bin$sex, levels=c(0,1), labels=c("F","M"))
heart_bin$cp = factor(heart_bin$cp, levels=c(1,2,3,4), labels=c("typical","atypical","no-anginal pain","asymptomatic"))
heart_bin$fbs = factor(heart_bin$fbs, levels=c(0,1), labels=c("no","si"))
heart_bin$restecg = factor(heart_bin$restecg, levels=c(0,1,2), labels=c("normal","abnormal","hypertrophy"))
heart_bin$exang = factor(heart_bin$exang, levels=c(0,1), labels=c("no","si"))
heart_bin$slope = factor(heart_bin$slope, levels=c(1,2,3), labels=c("upsloping","flat","downsloping"))
heart_bin$thal = factor(heart_bin$thal, levels=c(3,6,7), labels=c("normal","fixed","reversable"))
```

Di seguito una view del dataset oggetto di analisi e una verifica dell'eventuale presenza di valori missing:
```{r }
# View del dataset
head(heart_bin)

# Verfica di valori missing
sum(is.na(heart_bin))
```

## Analisi preliminare

Prima di andare a modellare la variabile di risposta in funzione delle caratteristiche del paziente, è utile analizzare preliminarmente i dati, mediante l'ausilio anche di strumenti grafici, al fine di esplorare la relazione tra la risposta e le variabili esplicative e di conseguenza facilitare la selezione o meno di quest'ultime nel modello.

A tal proposito, di seguito riportiamo gli stacked barplot tra la variabile di risposta *resp* e le varie variabili categoriche. Dal loro esame si nota che alcune di esse sembrerebbero avere un effetto sulla risposta in quanto almeno una delle loro categorie presenta una stima della probabilità di avere una cardiopatia decisamente diversa dalle restanti categorie, come ad esempio nel caso della variabile *sex* per cui la probabilità stimata negli uomini (55%) risulta più del doppio di quella nelle donne (26%). Al contrario per la variabile *fbms* le proabbilità nei due gruppi risultano molto simili (45% per *no* e 49% per *si*) e di conseguenza essa sembrerebbe non avere effetto sulla risposta.
```{r, message=FALSE}
# Stacked barplot
data_stacked = heart_bin %>% group_by(sex, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g1 = ggplot(data_stacked, aes(x=sex, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

data_stacked = heart_bin %>% group_by(cp, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g2 = ggplot(data_stacked, aes(x=cp, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

data_stacked = heart_bin %>% group_by(fbs, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g3 = ggplot(data_stacked, aes(x=fbs, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

data_stacked = heart_bin %>% group_by(restecg, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g4 = ggplot(data_stacked, aes(x=restecg, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

data_stacked = heart_bin %>% group_by(exang, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g5 = ggplot(data_stacked, aes(x=exang, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

data_stacked = heart_bin %>% group_by(slope, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g6 = ggplot(data_stacked, aes(x=slope, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

data_stacked = heart_bin %>% group_by(thal, resp) %>% summarize(n=n()) %>% mutate(perc=round(n/sum(n),4), perc_l=scales::percent(perc))
g7 = ggplot(data_stacked, aes(x=thal, y=perc, fill=resp)) + 
  geom_bar(stat="identity", position="fill") +
  scale_y_continuous(breaks=seq(0, 1, .25), label=percent) +
  geom_text(aes(label=perc_l), size=2.8, position=position_stack(vjust=0.5)) +
  theme_minimal() +
  scale_fill_manual(values=c("0"="lightblue","1"="cornflowerblue")) +
  labs(y="Percentuale")
rm(data_stacked)

grid.arrange(g1, g2, g3, g4, g5, g6, g7, nrow=4, ncol=2)
rm(g1, g2, g3, g4, g5, g6, g7)
```

Per quanto riguarda l'analisi delle variabili quantitative, plottiamo i valori osservati dei 303 pazienti, differentemente colorati in base alla risposta su di essi rilevata: in rosso se il paziente soffre di una malattia cardiaca, in blu se non soffre di tale tipo di malattia. Dal loro esame si osserva che variabili come *age* e *chol* sembrerebbero non avere un effetto sulla risposta in quanto i punti blu e rossi si sovrappongono. Al contrario per variabili come *oldpeak* e *ca* i punti rossi si trovano prevalentemente sopra o sotto a quelli blu e di conseguenza si pensa possano avere un effetto sulla variabile dipendente. In particolare per *oldpeak* i punti rossi si trovano per la maggior parte sopra quelli blu e pertanto sembra che all'aumentare della depressione ST sia più probabile che il paziente soffra di una cardiopatia.

```{r }
# Scatterplot
par(mfrow=c(3,2))
col_resp=c("blue","red")
plot(heart_bin$age, col=col_resp[heart_bin$resp], ylab="age", xlab="")
legend("topleft", title="resp", cex = 0.4, legend=levels(heart_bin$resp), fill=col_resp)
plot(heart_bin$trestbps, col=col_resp[heart_bin$resp], ylab="trestbps", xlab="")
legend("topleft", title="resp", cex = 0.4, legend=levels(heart_bin$resp), fill=col_resp)
plot(heart_bin$chol, col=col_resp[heart_bin$resp], ylab="chol", xlab="")
legend("topleft", title="resp", cex = 0.4, legend=levels(heart_bin$resp), fill=col_resp)
plot(heart_bin$thalach, col=col_resp[heart_bin$resp], ylab="thalach", xlab="")
legend("topleft", title="resp", cex = 0.4, legend=levels(heart_bin$resp), fill=col_resp)
plot(heart_bin$oldpeak, col=col_resp[heart_bin$resp], ylab="oldpeak", xlab="")
legend("topleft", title="resp", cex = 0.4, legend=levels(heart_bin$resp), fill=col_resp)
plot(heart_bin$ca, col=col_resp[heart_bin$resp], ylab="ca", xlab="")
legend("topleft", title="resp", cex = 0.4, legend=levels(heart_bin$resp), fill=col_resp)
rm(col_resp)
```

A conclusioni simili si giunge anche tramite l'osservazione dei boxplot riportati di seguito: ad esempio per la variabile *chol* i boxplot nei due gruppi sono pressochè uguali a testimonianza che tale variabile non sembra avere una relazione con la variabile di risposta.

```{r }
# Boxplot
g1 = ggplot(heart_bin, aes(x=resp, y=age)) +
  geom_boxplot(fill="lightblue", alpha=0.5, notch=F) +
  theme_minimal()
g2 = ggplot(heart_bin, aes(x=resp, y=chol)) +
  geom_boxplot(fill="lightblue", alpha=0.5, notch=F) +
  theme_minimal()
g3 = ggplot(heart_bin, aes(x=resp, y=trestbps)) +
  geom_boxplot(fill="lightblue", alpha=0.5, notch=F) +
  theme_minimal()
g4 = ggplot(heart_bin, aes(x=resp, y=thalach)) +
  geom_boxplot(fill="lightblue", alpha=0.5, notch=F) +
  theme_minimal()
g5 = ggplot(heart_bin, aes(x=resp, y=oldpeak)) +
  geom_boxplot(fill="lightblue", alpha=0.5, notch=F) +
  theme_minimal()
g6 = ggplot(heart_bin, aes(x=resp, y=ca)) +
  geom_boxplot(fill="lightblue", alpha=0.5, notch=F) +
  theme_minimal()
grid.arrange(g1, g2, g3, g4, g5, g6, nrow=3, ncol=2)
rm(g1, g2, g3, g4, g5, g6)
```

Infine, analizziamo anche la correlazione lineare tra le varie variabili quantitative mediante il correlation plot.

```{r }
#### Correlazione variabili quantitative ####
library(ggcorrplot)
matrix_corrplot = round(cor(select_if(heart_bin, is.numeric), method="pearson"),4)
ggcorrplot(matrix_corrplot, hc.order=T, type="lower", lab=T)
rm(matrix_corrplot)
```

# Modellazione statistica

Avendo a che fare con una variabile di risposta binaria (assenza/presenza di una malattia cardiaca), un modello che ben rappresenta il fenomeno di studio è il modello di regressione logistica con la funzione logit come funzione link.

Prima di cominciare con la selezione delle variabili esplicative e pertanto con la ricerca del modello più adeguato, raggruppiamo le categorie *abnormal* e *hypertrophy* della variabile *restecg* in un'unica categoria in quanto la modalità *abnromal* presenta soltanto 4 osservazioni. Inoltre, raggruppiamo anche le modalità della variabile *cp* relativa al tipo di dolore toracico. Le due nuove variabili create, *restecg_class* e *cp_class*, sono le seguenti:
```{r }
#### Creazione nuove categorie per le variabili restecg e cp ####
heart_bin = heart_bin %>% mutate(restecg_class=factor(ifelse(restecg=="normal",0,1),labels=c("normal","hypertrophy")))
heart_bin = heart_bin %>% mutate(cp_class=factor(ifelse(cp=="asymptomatic",0,1),labels=c("asymptomatic","symptomatic")))
```

La selezione delle variabili esplicative è stata fatta manualmente step by step, aggiungendo di volta in volta una variabile, una sua trasformata o un effetto di interazione al modello precedente e poi andando a testare la significatività di tale effetto. Al fine di rendere più agevole la trattazione, non riportiamo tutti gli step effettuati bensì soltanto degli esempi che mostrano come abbiamo generalmente deciso di selezionare o meno una variabile e pertanto come siamo arrivati, step by step, al modello finale.

Come primo passo, abbiamo aggiunto al modello nullo, ovvero quello con la sola intercetta, la variabile *sex* rappresentante il genere del paziente:
```{r }
# Selezione manuale - Step 1
mod1 = glm(resp~sex, family=binomial(link=logit), data=heart_bin)
summary(mod1)
```

Dall'output del modello si può concludere che l'ipotesi nulla $H_0: \beta_{maschio}=0$ viene rifiutata ad un livello di significatività dell'0.10% in quanto il p-value risulta inferiore a tale valore. Pertanto la variabile *sex* ha un effetto statisticamente significativo sulla risposta e ciò è in linea con quanto emerso dall'analisi grafica effettuata in precedenza.

Aggiungiamo ora al modello la variabile *cp_class*. Notiamo che anche tale variabile risulta avere un effetto statisticamente significativo e pertanto risulta adeguato aggiungerla al modello.
```{r }
# Selezione manuale - Step 2
mod2 = glm(resp~sex+cp_class, family=binomial(link=logit), data=heart_bin)
summary(mod2)
```

Al fine di verificare che il modello con l'aggiunta di *cp_class* (*mod2*) sia migliore di quello senza tale variabile (*mod1*), facciamo il test per modelli nested, dal quale emerge il rifiuto dell'ipotesi nulla $H_0: mod1$, ovvero porta a rifiutare come più adatto il modello con meno regressori. Si giunge alla medesima conclusione anche mediante i criteri AIC e BIC: il modello *mod2* presenta valori decisamente più piccoli rispetto al modello *mod1*.
```{r }
# Confronto modello 1 e modello 2
anova(mod1, mod2, test='Chisq')
AIC(mod1,mod2)
BIC(mod1,mod2)
```

Aggiungendo invece la variabile *fbs* ci accorgiamo come questa non abbia un effetto statisticamente significativo sulla presenza o meno di una malattia cardiaca, confermando quanto anticipato mediante l'analisi grafica precedentemente svolta. Il test per modelli nested, AIC e BIC mostrano come il modello *mod2* sia da preferire al modello con l'aggiunta di *fbs* (*mod3*).
```{r }
# Selezione manuale - Step 3
mod3 = glm(resp~sex+cp_class+fbs, family=binomial(link=logit), data=heart_bin)
summary(mod3)
anova(mod2, mod3, test='Chisq')
AIC(mod2,mod3)
BIC(mod2,mod3)
```

Mediante la selezione manuale delle variabili esplicative, siamo arrivati ad individuare il modello riportato di seguito. Oltre all'output relativo ad esso, riportiamo anche l'output dell'istruzione *Anova* che mostra i risultati dei test per il compare dei modelli nested: partendo dall'alto, per ogni variabile aggiunta al modello, vengono confrontati il modello con tale variabile e quello ridotto senza di essa. Per tutte le variabili il test risulta significativo almeno ad un livello di significatività del 10%; ciò significa che, per ogni variabile aggiunta, viene sempre preferito il modello più complesso a quello ridotto (ad un livello di significatività di almeno il 10%).
```{r }
# Selezione manuale - Modello finale
mod_manual = glm(resp~sex+cp_class+thal+slope+oldpeak+ca+trestbps, family=binomial(link=logit), data=heart_bin)
summary(mod_manual)
Anova(mod_manual)
```

A questo punto abbiamo deciso di selezionare le variabili esplicative anche mediante i metodi di selezione automatica *backward elimination* e *forward selection*. I modelli individuati tramite questi due metodi risultano uguali, pertanto consideriamo soltanto quello ottenuto con la *backward elimination*.
```{r }
# Selezione automatica - Modelli backward e forward
#mod_null = glm(resp~1, family=binomial(link=logit), data=heart_bin[,-c(3,7)])
mod_full = glm(resp~., family=binomial(link=logit), data=heart_bin[,-c(3,7)])

mod_backward = stepAIC(mod_full, direction="backward")
summary(mod_backward)

#mod_forward = stepAIC(mod_null, direction="forward", scope=list(lower=mod_null,upper=mod_full))
#summary(mod_forward)

rm(mod_full)
```

I modelli individuati tramite la selezione manuale e automatica delle variabili esplicative risultano nested; infatti il modello "automatico" (*mod_backward*) contiene due variabili in più, in particolare *exang* e *restecg*, rispetto a quello "manuale" (*mod_manual*). Dal confronto fra i modelli si nota che il loro fitting risulta simile: il test per modelli nested risulta significativo solo ad un livello di significatività del 10%, il valore dell'AIC è migliore per il modello di selezione automatica, mentre il BIC per quello di selezione manuale. A seguito di tutto ciò, optiamo per il modello di selezione manuale in quanto nel modello di selezione automatica sono presenti più variabili con un effetto che risulta statisticamente non significativo. Ovviamente per una più corretta scelta delle variabili sarebbe opportuno conoscere a fondo il fenomeno di interesse e pertanto è consigilabile avere un confronto con esperti del settore.
```{r }
# Confronto modelli di selezione manuale e automatica
anova(mod_manual, mod_backward, test='Chisq')
AIC(mod_manual, mod_backward)
BIC(mod_manual, mod_backward)
```

Una volta individuato il modello che secondo noi descrive bene il fenomeno di interesse, possiamo passare all'interpretazione dei coefficienti stimati e dei rispettivi intervalli di confidenza. Di seguito riportiamo l'interpretazione di alcuni di essi:

* La propensione di contrarre una malattia cardiaca è circa 3 volte più alta negli uomini rispetto alle donne. Inoltre, si può affermare che la propensione negli uomini rispetto alle donne risulta almeno maggiore del 34% fino ad un massimo di 8 volte tanto.
* L'odds ratio dei pazienti con un dolore al petto sintomatico è inferiore di circa l'88% rispetto a quelli con un dolore asintomatico; ciò significa che la probabilità di avere una cardiopatia è minore per quei pazienti che presentano un dolore al petto sintomatico.
* La propensione di avere una cardiopatia è circa 4 voltè più alta per quei pazienti il cui risultato del test da sforzo al tallio ha dato un difetto reversibile rispetto a quelli che hanno avuto dei risultati normali. Al contrario, non c'è una differenza statisticamente significativa nella propensione alla cardiopatia per i pazienti i cui risultati hanno dato un difetto fisso rispetto a quei pazienti con risutati normali; questo lo si evince sia dall'intervallo di confidenza di $e^{\beta_{fixed}}$ che contiene il valore 1 sia dalla summary del modello, dove il p-value relativo a tale coefficiente risulta estremamente alto, e quindi a favore dell'ipotesi nulla $H_0:\beta_{fixed}=0$.
* La propensione di avere una malattia al cuore aumenta all'aumentare del numero di vasi sanguigni colorati. Ad esempio la propensione per i pazienti che hanno due vasi sanguigni colorati è maggiore di circa 11 volte ($e^{2\hat{\beta_{ca}}}=11.46$) rispetto ai pazienti per i quali la fluoroscopia non ha rilevato vasi sanguigni colorati.
```{r }
# Interpretazione dei coefficienti e dei rispettivi IC
exp(cbind(coef(mod_manual), confint.default(mod_manual)))
exp(2*coef(mod_manual)[9]) #aumento di 2 vasi sanguigni colorati per la variabile "ca"
```

Infine, di seguito riportiamo anche un grafico che aiuta nell'interpretazione dei parametri stimati:
```{r }
plot_model(mod_manual, sort.est=T)
```

# Valutazione della bontà del modello

Dopo aver individuato il modello che per noi spiega nel modo migliore il fenomeno studiato, andiamo a valutare la sua capacità previsionale e classificatoria. A tal fine calcoliamo i valori previsti dei 303 pazienti e poi classifichiamo quest'ultimi sulla base della seguente regola decisionale: se il paziente presenta un valore previsto superiore a 0.50 allora tale paziente verrà classificato come affetto da una malattia al cuore, in caso contrario come sano. Infine, costruiamo la matrice di confusione derivante da tale regola decisionale.
```{r }
# Valori previsti
previsti = predict(mod_manual, type="response")

# Matrice di confusione
previsti0.5 = factor(ifelse(previsti<=0.5,0,1))
confusionMatrix(previsti0.5, heart_bin$resp, positive="1")
```

Esaminando l'output della matrice di confusione si nota che l'accuratezza del test, ovvero la percentuale di una corretta classificazione, è superiore a 0.80 (*(145+115)/303=0.8581*). Inoltre, anche la specificità (*145/(145+19)=0.8841*), ovvero la capacità di individuare come negativi i pazienti sani, e la sensibilità, ovvero la capacità di individuare come positivi i pazienti malati (*115/(115+24)=0.8273*), sono superiori a 0.80. Pertanto, il modello stimato e la regola decisionale adotatta permettono di avere una buona capacità previsionale/classificatoria.

Al fine di valutare complessivamente la capacità previsionale del modello e non solo sulla base di un determinato valore soglia (o cut-off), andiamo ad esaminare la curva ROC che mostra i livelli di sensibilità e (1-specificità) per tutti i possibili cut-off. La curva ROC ottenuta risulta vicina all'angolo in alto a sinistra e l'area sottesa ad essa (AUC - area under the curve) presenta un valore pari a 0.9266. Pertanto, il modello risulta altamente accurato e con ottime capcità previsionali/classificatorie.

```{r }
# Curva ROC
par(mfrow=c(1,1))
roc(heart_bin$resp~previsti, col="red", plot=T, print.auc=T, legacy.axes=T, main="Curva ROC")
```

Per concludere, una volta che il modello è stato validato può essere utilizzato per stimare la probabilità di avere una malattia cardiaca per nuovi pazienti. A titolo esemplificativo, supponiamo ad esempio di avere un nuovo paziente di genere maschile per cui i risultati dei test diagnostici sono abbastanza preoccpanti; la probabilità per tale paziente di avere una malattia cardiaca risulta addirittura pari a 0.99.

```{r }
#### Utilizzo del modello per nuovi pazienti ####
nuovo_paziente = data.frame(sex = "M",
                            cp_class = "asymptomatic",
                            trestbps = mean(heart_bin$trestbps),
                            oldpeak = mean(heart_bin$oldpeak),
                            slope = "upsloping",
                            ca = 3,
                            thal = "reversable")
predict(mod_manual, type="response", nuovo_paziente)
```
